{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training code for dataset Bla Bla\n",
    "\n",
    "Description of the dataset, experiment etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from careamics.lightning import VAEModule\n",
    "\n",
    "from microsplit_reproducibility.configs.factory import (\n",
    "    get_algorithm_config,\n",
    "    get_likelihood_config,\n",
    "    get_loss_config,\n",
    "    get_model_config,\n",
    "    get_optimizer_config,\n",
    "    get_training_config,\n",
    "    get_lr_scheduler_config,\n",
    ")\n",
    "from microsplit_reproducibility.datasets import create_train_val_datasets\n",
    "from microsplit_reproducibility.utils.utils import plot_training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsplit_reproducibility.configs.parameters.pavia_p24 import get_denoisplit_parameters\n",
    "from microsplit_reproducibility.configs.data.pavia_p24 import get_data_configs\n",
    "from microsplit_reproducibility.datasets.pavia_p24 import get_train_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configs\n",
    "\n",
    "Example training code 5 epochs, switch between full training, short training,  fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO refactor, wrap in one function. Only if the function can be generalized\n",
    "train_data_config, val_data_config, test_data_configs = get_data_configs()\n",
    "training_params = get_denoisplit_parameters()\n",
    "# TODO nm path with pooch ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in train_data_config:\n",
    "    print(k)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_local_path = \"/localscratch/data/pavia3_sequential_cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pooch.create(\n",
    "    # path=pooch.os_cache(\"microsplit_reproducibility_pavia_p24\"), # TODO should be downloaded and stored locally\n",
    "    path=tmp_local_path,\n",
    "    base_url=\"\",\n",
    "    registry={\"\":\"\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, val_dset, _, data_stats = create_train_val_datasets(\n",
    "    datapath=tmp_local_path,\n",
    "    train_config=train_data_config,\n",
    "    val_config=val_data_config,\n",
    "    test_config=val_data_config,\n",
    "    load_data_func=get_train_val_data,\n",
    ")\n",
    "\n",
    "# TODO problem is, creating a dataloader requires a config, that's ugly af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    num_workers=training_params[\"num_workers\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    num_workers=training_params[\"num_workers\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params[\"data_stats\"] = data_stats # TODO rethink\n",
    "\n",
    "loss_config = get_loss_config(**training_params)\n",
    "model_config = get_model_config(**training_params)\n",
    "gaussian_lik_config, noise_model_config, nm_lik_config = get_likelihood_config(\n",
    "    **training_params\n",
    ")\n",
    "training_config = get_training_config(**training_params)\n",
    "lr_scheduler_config = get_lr_scheduler_config(**training_params)\n",
    "optimizer_config = get_optimizer_config(**training_params)\n",
    "\n",
    "# TODO rename to create\n",
    "experiment_config = get_algorithm_config(\n",
    "    algorithm=training_params[\"algorithm\"],\n",
    "    loss_config=loss_config,\n",
    "    model_config=model_config,\n",
    "    gaussian_lik_config=gaussian_lik_config,\n",
    "    nm_config=noise_model_config,\n",
    "    nm_lik_config=nm_lik_config,\n",
    "    lr_scheduler_config=lr_scheduler_config,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO code, discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Only 5 epochs for the sake of the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init lightning model\n",
    "lightning_model = VAEModule(algorithm_config=experiment_config)\n",
    "\n",
    "# train the model\n",
    "# custom_callbacks = get_callbacks(logdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=training_config.num_epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    # callbacks=custom_callbacks,\n",
    "    precision=training_config.precision,\n",
    "    gradient_clip_val=training_config.gradient_clip_val,\n",
    "    gradient_clip_algorithm=training_config.gradient_clip_algorithm,\n",
    "    # num_sanity_val_steps=0\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "        train_dataloaders=train_dloader,\n",
    "        val_dataloaders=val_dloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(\"csv_logs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
