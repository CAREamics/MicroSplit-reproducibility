{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation code for the dataset Bla bla\n",
    "\n",
    "To address the intensity scale differences between low-SNR inputs and high-SNR groundtruth images in fluorescence microscopy, we used modified versions of PSNR, SSIM, and MS-SSIM that account for these variations:\n",
    "\n",
    "MicroSSIM & MicroMS-SSIM: Variants of SSIM and MS-SSIM, where predictions are scaled by an optimal scalar. Both the scaled predictions and groundtruth are then normalized before computing the metrics using the original SSIM or MS-SSIM formulas.\n",
    "\n",
    "CARE-PSNR: A PSNR variant from CARE [ref], where an optimal scaling factor is applied to the predictions, and PSNR is computed between the scaled predictions and the groundtruth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important ! \n",
    "\n",
    "This step has to be executed in order to get predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from microsplit_reproducibility.configs.factory import (\n",
    "    create_algorithm_config,\n",
    "    get_likelihood_config,\n",
    "    get_loss_config,\n",
    "    get_model_config,\n",
    "    get_optimizer_config,\n",
    "    get_training_config,\n",
    "    get_lr_scheduler_config,\n",
    ")\n",
    "from microsplit_reproducibility.utils.io import load_checkpoint\n",
    "from microsplit_reproducibility.utils.utils import (\n",
    "    plot_input_patches,\n",
    "    plot_individual_samples,\n",
    ")\n",
    "from microsplit_reproducibility.datasets import create_train_val_datasets\n",
    "\n",
    "from careamics.lightning import VAEModule\n",
    "from careamics.lvae_training.eval_utils import (\n",
    "    get_predictions,\n",
    "    plot_error,\n",
    "    get_single_file_predictions,\n",
    ")\n",
    "from careamics.utils.metrics import avg_range_invariant_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsplit_reproducibility.configs.parameters.HT_LIF24 import get_microsplit_parameters\n",
    "from microsplit_reproducibility.configs.data.HT_LIF24 import get_data_configs\n",
    "from microsplit_reproducibility.datasets.HT_LIF24 import get_train_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pooch.create(\n",
    "    path=\"./data\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\"ht_lif24.zip\": None},\n",
    ")\n",
    "\n",
    "NOISE_MODELS = pooch.create(\n",
    "    path=\"./noise_models\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\n",
    "        \"nm_ht_lif24_ch1_20ms.npz\": None,\n",
    "        \"nm_ht_lif24_ch2_20ms.npz\": None,\n",
    "        \"nm_ht_lif24_ch3_20ms.npz\": None,\n",
    "    },\n",
    ")\n",
    "\n",
    "MODEL_CHECKPOINTS = pooch.create(\n",
    "    path=\"./checkpoints\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\"best.ckpt\": None},\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(NOISE_MODELS.registry):\n",
    "    NOISE_MODELS.fetch(f\"nm_ht_lif24_ch{i+1}_20ms.npz\")\n",
    "\n",
    "# DATA.fetch(\"ht_lif24.zip\", processor=pooch.Unzip())\n",
    "\n",
    "for f in MODEL_CHECKPOINTS.registry:\n",
    "    MODEL_CHECKPOINTS.fetch(f\"{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_config, val_data_config, test_data_configs = get_data_configs(dset_type=\"20ms\")\n",
    "experiment_params = get_microsplit_parameters(dset_type=\"20ms\", nm_path=NOISE_MODELS.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, val_dset, test_dset, data_stats = create_train_val_datasets(\n",
    "    datapath=DATA.path / \"ht_lif24.zip.unzip/ht_lif24\",\n",
    "    train_config=train_data_config,\n",
    "    val_config=val_data_config,\n",
    "    test_config=val_data_config,\n",
    "    load_data_func=get_train_val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get experiment configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params[\"data_stats\"] = data_stats\n",
    "\n",
    "loss_config = get_loss_config(**experiment_params)\n",
    "model_config = get_model_config(**experiment_params)\n",
    "gaussian_lik_config, noise_model_config, nm_lik_config = get_likelihood_config(\n",
    "    **experiment_params\n",
    ")\n",
    "training_config = get_training_config(**experiment_params)\n",
    "lr_scheduler_config = get_lr_scheduler_config(**experiment_params)\n",
    "optimizer_config = get_optimizer_config(**experiment_params)\n",
    "\n",
    "# TODO rename to create\n",
    "experiment_config = create_algorithm_config(\n",
    "    algorithm=experiment_params[\"algorithm\"],\n",
    "    loss_config=loss_config,\n",
    "    model_config=model_config,\n",
    "    gaussian_lik_config=gaussian_lik_config,\n",
    "    nm_config=noise_model_config,\n",
    "    nm_lik_config=nm_lik_config,\n",
    "    lr_scheduler_config=lr_scheduler_config,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_input_patches(dataset=test_dset, num_channels=3, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEModule(algorithm_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the model to inference mode\n",
    "(Optional) \n",
    "Change the tile size to reduce the appearance of tiling artifacts. The combination of \n",
    "# TODO add explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.reset_for_inference(tile_size=[256, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_checkpoint(\"checkpoints\", best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt[\"state_dict\"], strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples from the model\n",
    "\n",
    "Here we display a single sample of one image from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples to plot\n",
    "num_samples = 2\n",
    "stitched_samples = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    stitched_samples.append(\n",
    "        get_single_file_predictions(\n",
    "            model=model,\n",
    "            dset=test_dset,\n",
    "            tile_size=[256, 256],\n",
    "            batch_size=8,\n",
    "            num_workers=experiment_params[\"num_workers\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize individual samples\n",
    "\n",
    "Might create tiling artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_samples(stitched_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might need to reset the input size for computing mmse prediction\n",
    "model.model.reset_for_inference(tile_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_predictions, stitched_stds = get_predictions(\n",
    "    model=model,\n",
    "    dset=test_dset,\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    num_workers=experiment_params[\"num_workers\"],\n",
    "    mmse_count=experiment_params[\"mmse_count\"],\n",
    "    tile_size=model.model.image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename\n",
    "filename_idx = str(test_dset._fpath).split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "target = test_dset._data[..., :-1]\n",
    "predictions = stitched_predictions[filename_idx][..., :-1]\n",
    "\n",
    "sep_mean = np.transpose(data_stats[0].numpy(), axes=(0, 2, 3, 1))\n",
    "sep_std = np.transpose(data_stats[1].numpy(), axes=(0, 2, 3, 1))\n",
    "\n",
    "target_normalized = (target - sep_mean) / sep_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnormalized = []\n",
    "for i in range(predictions.shape[-1]):\n",
    "    if sep_std.shape[-1] == 1:\n",
    "        temp_pred_unnorm = predictions[...,i] * sep_std[...,0] + sep_mean[...,0]\n",
    "    else:\n",
    "        temp_pred_unnorm = predictions[...,i] * sep_std[...,i] + sep_mean[...,i]\n",
    "    pred_unnormalized.append(temp_pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One random target vs predicted image (patch of shape [sz x sz])\n",
    "ncols = target.shape[-1]\n",
    "_, ax = plt.subplots(figsize=(ncols * 5, 3 * 5), nrows=3, ncols=2)\n",
    "img_idx = 10\n",
    "sz = 800\n",
    "hs = np.random.randint(target.shape[1] - sz)\n",
    "ws = np.random.randint(target.shape[2] - sz)\n",
    "for i in range(ncols):\n",
    "    ax[i, 0].set_title(f\"Target Channel {i+1} for {filename_idx}\")\n",
    "    ax[i, 0].imshow(target[0, hs : hs + sz, ws : ws + sz, i])\n",
    "    ax[i, 1].set_title(f\"Predicted Channel {i+1} for {filename_idx}\")\n",
    "    ax[i, 1].imshow(predictions[0, hs : hs + sz, ws : ws + sz, i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = predictions.shape[-1]\n",
    "img_sz = 3\n",
    "_, ax = plt.subplots(figsize=(4 * img_sz, nrows * img_sz), ncols=4, nrows=nrows)\n",
    "idx = np.random.randint(len(predictions))\n",
    "print(idx)\n",
    "for ch_id in range(nrows):\n",
    "    ax[ch_id, 0].set_title(f\"Target Channel {ch_id+1}\")\n",
    "    ax[ch_id, 0].imshow(target_normalized[idx, ..., ch_id], cmap=\"magma\")\n",
    "    ax[ch_id, 1].set_title(f\"Predicted Channel {ch_id+1}\")\n",
    "    ax[ch_id, 1].imshow(predictions[idx, :, :, ch_id], cmap=\"magma\")\n",
    "    plot_error(\n",
    "        target_normalized[idx, ..., ch_id],\n",
    "        predictions[idx, :, :, ch_id],\n",
    "        cmap=mpl.cm.coolwarm,\n",
    "        ax=ax[ch_id, 2],\n",
    "        max_val=None,\n",
    "    )\n",
    "\n",
    "    cropsz = 256\n",
    "    h_s = np.random.randint(0, target_normalized.shape[1] - cropsz)\n",
    "    h_e = h_s + cropsz\n",
    "    w_s = np.random.randint(0, target_normalized.shape[2] - cropsz)\n",
    "    w_e = w_s + cropsz\n",
    "\n",
    "    plot_error(\n",
    "        target_normalized[idx, h_s:h_e, w_s:w_e, ch_id],\n",
    "        predictions[idx, h_s:h_e, w_s:w_e, ch_id],\n",
    "        cmap=mpl.cm.coolwarm,\n",
    "        ax=ax[ch_id, 3],\n",
    "        max_val=None,\n",
    "    )\n",
    "\n",
    "    # Add rectangle to the region\n",
    "    rect = patches.Rectangle(\n",
    "        (w_s, h_s), w_e - w_s, h_e - h_s, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    "    )\n",
    "    ax[ch_id, 2].add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr = []\n",
    "psnr_arr = []\n",
    "rinv_psnr_arr = []\n",
    "ssim_arr = []\n",
    "for ch_id in range(predictions.shape[-1]):\n",
    "    rmse = np.sqrt(\n",
    "        ((predictions[..., ch_id] - target_normalized[..., ch_id]) ** 2)\n",
    "        .reshape(len(predictions), -1)\n",
    "        .mean(axis=1)\n",
    "    )\n",
    "    rmse_arr.append(rmse)\n",
    "    rinv_psnr = avg_range_invariant_psnr(\n",
    "        target_normalized[..., ch_id].copy(), predictions[..., ch_id].copy()\n",
    "    )\n",
    "    ssim_mean, ssim_std = avg_ssim(target[...,ch_id], pred_unnormalized[ch_id])\n",
    "    rinv_psnr_arr.append(rinv_psnr)\n",
    "    ssim_arr.append((ssim_mean,ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RangeInvPSNR: \", \" <--> \".join([str(x) for x in rinv_psnr_arr]))\n",
    "print(\"MicroSSIM: \", \" <--> \".join([f\"{round(x,3)}±{round(y,4)}\" for (x, y) in ssim_arr]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "for file in test_dset.dsets:\n",
    "    # get the filename without the path and extension\n",
    "    filename = file._fpath.split(\"/\")[-1].split(\".\")[0]\n",
    "    tifffile.imwrite(\n",
    "        f\"predictions/prediction_{filename}.tif\", stitched_predictions[filename]\n",
    "    )\n",
    "    tifffile.imwrite(f\"predictions/std_{filename}.tif\", stitched_stds[filename])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
