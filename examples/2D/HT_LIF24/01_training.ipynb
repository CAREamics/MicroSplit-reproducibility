{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training code for dataset Bla Bla\n",
    "\n",
    "Description of the dataset, experiment etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important ! \n",
    "\n",
    "This step can be skipped! Only run this notebook if you want to train the microsplit model from scratch or finetune. Pretrained model checkpoint is available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from careamics.lightning import VAEModule\n",
    "from careamics.lvae_training.dataset import DataSplitType\n",
    "\n",
    "from microsplit_reproducibility.configs.factory import (\n",
    "    create_algorithm_config,\n",
    "    get_likelihood_config,\n",
    "    get_loss_config,\n",
    "    get_model_config,\n",
    "    get_optimizer_config,\n",
    "    get_training_config,\n",
    "    get_lr_scheduler_config,\n",
    ")\n",
    "from microsplit_reproducibility.utils.callbacks import get_callbacks\n",
    "from microsplit_reproducibility.utils.io import load_checkpoint\n",
    "from microsplit_reproducibility.datasets import create_train_val_datasets\n",
    "from microsplit_reproducibility.utils.utils import plot_training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsplit_reproducibility.configs.parameters.HT_LIF24 import get_microsplit_parameters\n",
    "from microsplit_reproducibility.configs.data.HT_LIF24 import get_data_configs\n",
    "from microsplit_reproducibility.datasets.HT_LIF24 import get_train_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and experiment parameters\n",
    "\n",
    "Example training code 5 epochs, switch between full training, short training,  fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_config, val_data_config, test_data_configs = get_data_configs(dset_type=\"20ms\")\n",
    "experiment_params = get_microsplit_parameters(dset_type=\"20ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in train_data_config:\n",
    "    print(k)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pooch.create(\n",
    "    path=\"./data\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\"ht_lif24.zip\": None},\n",
    ")\n",
    "\n",
    "NOISE_MODELS = pooch.create(\n",
    "    path=\"./noise_models\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\"nm_ht_lif24_ch1_20ms.npz\": None,\n",
    "              \"nm_ht_lif24_ch2_20ms.npz\": None,\n",
    "              \"nm_ht_lif24_ch3_20ms.npz\": None},\n",
    ")\n",
    "\n",
    "MODEL_CHECKPOINTS = pooch.create(\n",
    "    path=\"./checkpoints\",\n",
    "    base_url=\"https://download.fht.org/jug/ht_lif24\",\n",
    "    registry={\"best.ckpt\": None,\n",
    "              \"last.ckpt\": None},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(NOISE_MODELS.registry):\n",
    "    NOISE_MODELS.fetch(f\"nm_ht_lif24_ch{i+1}_20ms.npz\")\n",
    "\n",
    "DATA.fetch(\"ht_lif24.zip\", processor=pooch.Unzip())\n",
    "\n",
    "for f in MODEL_CHECKPOINTS.registry:\n",
    "    MODEL_CHECKPOINTS.fetch(f\"{f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, val_dset, _, data_stats = create_train_val_datasets(\n",
    "    datapath=DATA.path / \"ht_lif24.zip.unzip/ht_lif24\",\n",
    "    train_config=train_data_config,\n",
    "    val_config=val_data_config,\n",
    "    test_config=val_data_config,\n",
    "    load_data_func=get_train_val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    num_workers=experiment_params[\"num_workers\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=experiment_params[\"batch_size\"],\n",
    "    num_workers=experiment_params[\"num_workers\"],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO grid of input patches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get experiment configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_params[\"data_stats\"] = data_stats # TODO rethink\n",
    "\n",
    "loss_config = get_loss_config(**experiment_params)\n",
    "model_config = get_model_config(**experiment_params)\n",
    "gaussian_lik_config, noise_model_config, nm_lik_config = get_likelihood_config(\n",
    "    **experiment_params\n",
    ")\n",
    "training_config = get_training_config(**experiment_params)\n",
    "lr_scheduler_config = get_lr_scheduler_config(**experiment_params)\n",
    "optimizer_config = get_optimizer_config(**experiment_params)\n",
    "\n",
    "experiment_config = create_algorithm_config(\n",
    "    algorithm=experiment_params[\"algorithm\"],\n",
    "    loss_config=loss_config,\n",
    "    model_config=model_config,\n",
    "    gaussian_lik_config=gaussian_lik_config,\n",
    "    nm_config=noise_model_config,\n",
    "    nm_lik_config=nm_lik_config,\n",
    "    lr_scheduler_config=lr_scheduler_config,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEModule(algorithm_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint (optional)\n",
    "\n",
    "It's possible to load a checkpoint to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = load_checkpoint(\"checkpoints\", best=False)\n",
    "model = VAEModule.load_from_checkpoint(ckpt, algorithm_config=experiment_config) # TODO fix seek error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Only 5 epochs for the sake of the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=training_config.num_epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=get_callbacks(\".\"),\n",
    "    precision=training_config.precision,\n",
    "    gradient_clip_val=training_config.gradient_clip_val,\n",
    "    gradient_clip_algorithm=training_config.gradient_clip_algorithm,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "        train_dataloaders=train_dloader,\n",
    "        val_dataloaders=val_dloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics(f\"csv_logs/{experiment_params['experiment_name']}/version_0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO grid of predictions of last epoch, input/ k channels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
